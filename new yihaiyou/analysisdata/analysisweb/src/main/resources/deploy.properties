#mysql
database.user=root
#database.user=wangxl
#database.url=jdbc:mysql://192.168.22.159/wxldb?useUnicode=true&characterEncoding=UTF-8
#database.password=wangxl123!
#database.url=jdbc:mysql://localhost/data?useUnicode=true&characterEncoding=UTF-8
#database.password=kingsley
database.url=jdbc:mysql://192.168.1.253/data?useUnicode=true&characterEncoding=UTF-8
database.password=test
database.driver=com.mysql.jdbc.Driver
database.maxWait=10
database.maxActive=10
database.maxIdle=5
database.testWhileIdle=true
database.validationQuery=select 1 from dual
hibernate.dialect=org.hibernate.dialect.MySQLDialect
#base hibernate config
hibernate.show_sql=true
hibernate.format_sql=false
hibernate.jdbc.batch_size=100
hibernate.jdbc.fetch_size=50
hibernate.autoReconnect=true
#hadoop
#fs.default.name
#hd.fs=hdfs://S00022:8020
hd.fs=hdfs://master:9000
#mapred.job.tracker
#hd.jt=S00022:50030
hd.jt=master:50030
#hive
hive.host=master
hive.port=10000
hive.url=jdbc:hive://${hive.host}:${hive.port}
hive.table=sale
hive.exec.drop.ignorenonexistent=true
#hbase
hbase.host=master
hbase.port=2181
#output
customeroutput=E:/mywork/code/zuiping/bigdata/data/
indexpath=E:/mywork/code/zuiping/bigdata/data/indexs/
#spark.master.url=spark://192.168.1.240:7077
jarpath=/opt/soft/plus
spark.master.url=local[*]
#spark.master.url=yarn-cluster
#jarpath=E:/mywork/code/zuiping/sparkdemo/jarPath/